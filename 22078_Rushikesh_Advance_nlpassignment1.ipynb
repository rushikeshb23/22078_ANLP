{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "odB9V8JNtO96"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wakCxh7Zm11",
        "outputId": "5994ad97-f7aa-4087-a136-32dafff6e69f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Corona_NLP_train (1).csv\", encoding='latin-1')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WO3Fl-J2tj38",
        "outputId": "5f45c9e8-b5fe-47c7-9fcf-9f19fc1d3020"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   UserName  ScreenName   Location     TweetAt  \\\n",
              "0      3799       48751     London  16-03-2020   \n",
              "1      3800       48752         UK  16-03-2020   \n",
              "2      3801       48753  Vagabonds  16-03-2020   \n",
              "3      3802       48754        NaN  16-03-2020   \n",
              "4      3803       48755        NaN  16-03-2020   \n",
              "\n",
              "                                       OriginalTweet           Sentiment  \n",
              "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
              "1  advice Talk to your neighbours family to excha...            Positive  \n",
              "2  Coronavirus Australia: Woolworths to give elde...            Positive  \n",
              "3  My food stock is not the only one which is emp...            Positive  \n",
              "4  Me, ready to go at supermarket during the #COV...  Extremely Negative  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b596c6da-17fc-4781-86db-3507364b6186\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserName</th>\n",
              "      <th>ScreenName</th>\n",
              "      <th>Location</th>\n",
              "      <th>TweetAt</th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3799</td>\n",
              "      <td>48751</td>\n",
              "      <td>London</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3800</td>\n",
              "      <td>48752</td>\n",
              "      <td>UK</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>advice Talk to your neighbours family to excha...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3801</td>\n",
              "      <td>48753</td>\n",
              "      <td>Vagabonds</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3802</td>\n",
              "      <td>48754</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>My food stock is not the only one which is emp...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3803</td>\n",
              "      <td>48755</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16-03-2020</td>\n",
              "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b596c6da-17fc-4781-86db-3507364b6186')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b596c6da-17fc-4781-86db-3507364b6186 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b596c6da-17fc-4781-86db-3507364b6186');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-845b3521-eb14-4b60-81d9-32f392cf7212\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-845b3521-eb14-4b60-81d9-32f392cf7212')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-845b3521-eb14-4b60-81d9-32f392cf7212 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 41157,\n  \"fields\": [\n    {\n      \"column\": \"UserName\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11881,\n        \"min\": 3799,\n        \"max\": 44955,\n        \"num_unique_values\": 41157,\n        \"samples\": [\n          34888,\n          39363,\n          3943\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ScreenName\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11881,\n        \"min\": 48751,\n        \"max\": 89907,\n        \"num_unique_values\": 41157,\n        \"samples\": [\n          79840,\n          84315,\n          48895\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12220,\n        \"samples\": [\n          \"Killeen, TX\",\n          \"Richmond VA\",\n          \"El Dorado\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TweetAt\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"12-04-2020\",\n          \"31-03-2020\",\n          \"08-04-2020\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OriginalTweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 41157,\n        \"samples\": [\n          \" Without the there would not be any problem whatsoever People are getting worried about the supply chain   Prices for key food staples are starting to soar in some parts of the world via\",\n          \"Rice &amp; wheat prices surge amid fears Covid-19 lockdown may threaten global food security\\r\\r\\nIncreased panic buying of food due to coronavirus lockdowns has led to price spikes for  world\\u00c2\\u0092s two staple grains, rice&amp; wheat. Importers rushed to stockpile goods\\r\\r\\n https://t.co/0qOv3jAp9m\",\n          \"When the government says to start social distancing, but you work retail so you can't just not talk to customers in the store lol fml I'm 100% going to catch covid-19\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Positive\",\n          \"Extremely Positive\",\n          \"Extremely Negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv(\"/content/drive/MyDrive/Corona_NLP_test.csv\", encoding='latin-1')\n",
        "df_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-YfR8PQBvk2H",
        "outputId": "10558d93-b30a-485b-db38-0e742bab6bcf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   UserName  ScreenName             Location     TweetAt  \\\n",
              "0         1       44953                  NYC  02-03-2020   \n",
              "1         2       44954          Seattle, WA  02-03-2020   \n",
              "2         3       44955                  NaN  02-03-2020   \n",
              "3         4       44956          Chicagoland  02-03-2020   \n",
              "4         5       44957  Melbourne, Victoria  03-03-2020   \n",
              "\n",
              "                                       OriginalTweet           Sentiment  \n",
              "0  TRENDING: New Yorkers encounter empty supermar...  Extremely Negative  \n",
              "1  When I couldn't find hand sanitizer at Fred Me...            Positive  \n",
              "2  Find out how you can protect yourself and love...  Extremely Positive  \n",
              "3  #Panic buying hits #NewYork City as anxious sh...            Negative  \n",
              "4  #toiletpaper #dunnypaper #coronavirus #coronav...             Neutral  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e3965a9b-36ae-49a8-8bfc-5707ed40d262\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserName</th>\n",
              "      <th>ScreenName</th>\n",
              "      <th>Location</th>\n",
              "      <th>TweetAt</th>\n",
              "      <th>OriginalTweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>44953</td>\n",
              "      <td>NYC</td>\n",
              "      <td>02-03-2020</td>\n",
              "      <td>TRENDING: New Yorkers encounter empty supermar...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>44954</td>\n",
              "      <td>Seattle, WA</td>\n",
              "      <td>02-03-2020</td>\n",
              "      <td>When I couldn't find hand sanitizer at Fred Me...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>44955</td>\n",
              "      <td>NaN</td>\n",
              "      <td>02-03-2020</td>\n",
              "      <td>Find out how you can protect yourself and love...</td>\n",
              "      <td>Extremely Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>44956</td>\n",
              "      <td>Chicagoland</td>\n",
              "      <td>02-03-2020</td>\n",
              "      <td>#Panic buying hits #NewYork City as anxious sh...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>44957</td>\n",
              "      <td>Melbourne, Victoria</td>\n",
              "      <td>03-03-2020</td>\n",
              "      <td>#toiletpaper #dunnypaper #coronavirus #coronav...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3965a9b-36ae-49a8-8bfc-5707ed40d262')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e3965a9b-36ae-49a8-8bfc-5707ed40d262 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e3965a9b-36ae-49a8-8bfc-5707ed40d262');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a2ee5ad6-f42d-4880-933b-ed83b2656604\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a2ee5ad6-f42d-4880-933b-ed83b2656604')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a2ee5ad6-f42d-4880-933b-ed83b2656604 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_test",
              "summary": "{\n  \"name\": \"df_test\",\n  \"rows\": 3798,\n  \"fields\": [\n    {\n      \"column\": \"UserName\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1096,\n        \"min\": 1,\n        \"max\": 3798,\n        \"num_unique_values\": 3798,\n        \"samples\": [\n          1071,\n          355,\n          882\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ScreenName\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1096,\n        \"min\": 44953,\n        \"max\": 48750,\n        \"num_unique_values\": 3798,\n        \"samples\": [\n          46023,\n          45307,\n          45834\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1717,\n        \"samples\": [\n          \"Ottawa, Canada\",\n          \"Lebanon\",\n          \"HousePriceMania\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TweetAt\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"11-03-2020\",\n          \"13-03-2020\",\n          \"02-03-2020\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OriginalTweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3798,\n        \"samples\": [\n          \"At my local grocery store in New Hampshire... #coronavirus #Covid_19 #NationalEmergency https://t.co/AXuMBSfNU9\",\n          \"Seeing resellers sell masks, alcohols and other necessities in prices which are 5-15x more expensive compared to SRPs makes me wonder how can people be so heartless, insensitive, and opportunistic in these times of crisis. #COVID2019\",\n          \"Where did coronavirus come from, and where will it take us? An interview with Rob Wallace, author of Big Farms Make Big Flu\\r\\r\\n\\r\\r\\nhttps://t.co/Hqp68iu1iN https://t.co/dR4Ys2hCOy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Positive\",\n          \"Neutral\",\n          \"Extremely Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wdx9T6JrJ-_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-Processing"
      ],
      "metadata": {
        "id": "bn4drNEWwXIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def preprocess_tweets(df):\n",
        "\n",
        "    def clean_tweet(text):\n",
        "        text = text.lower()\n",
        "        text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
        "        text = re.sub(r\"@\\w+\", \"\", text)\n",
        "        text = re.sub(r\"#\\w+\", \"\", text)\n",
        "        text = re.sub(r\"[^a-z0-9\\s]\", \" \", text)\n",
        "        text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "        return text\n",
        "\n",
        "    def simple_tokenize(text):\n",
        "        return text.split()\n",
        "\n",
        "    # Apply cleaning + tokenization\n",
        "    df['CleanTweet'] = df['OriginalTweet'].apply(clean_tweet)\n",
        "    df['Tokens'] = df['CleanTweet'].apply(simple_tokenize)\n",
        "\n",
        "    # Keep only CleanTweet, Tokens, and Sentiment\n",
        "    df = df[['CleanTweet', 'Tokens', 'Sentiment']]\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "m5qOJo7nwZmc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean = preprocess_tweets(df)\n",
        "df_clean.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "34DKXfoEwtLV",
        "outputId": "d1bac8e6-a9fb-4e83-c239-d9fc77063864"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          CleanTweet  \\\n",
              "0                                            and and   \n",
              "1  advice talk to your neighbours family to excha...   \n",
              "2  coronavirus australia woolworths to give elder...   \n",
              "3  my food stock is not the only one which is emp...   \n",
              "4  me ready to go at supermarket during the outbr...   \n",
              "\n",
              "                                              Tokens           Sentiment  \n",
              "0                                         [and, and]             Neutral  \n",
              "1  [advice, talk, to, your, neighbours, family, t...            Positive  \n",
              "2  [coronavirus, australia, woolworths, to, give,...            Positive  \n",
              "3  [my, food, stock, is, not, the, only, one, whi...            Positive  \n",
              "4  [me, ready, to, go, at, supermarket, during, t...  Extremely Negative  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-25c15d27-82b7-4bc0-84d6-8ce3f2ec0611\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CleanTweet</th>\n",
              "      <th>Tokens</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>and and</td>\n",
              "      <td>[and, and]</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>advice talk to your neighbours family to excha...</td>\n",
              "      <td>[advice, talk, to, your, neighbours, family, t...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>coronavirus australia woolworths to give elder...</td>\n",
              "      <td>[coronavirus, australia, woolworths, to, give,...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>my food stock is not the only one which is emp...</td>\n",
              "      <td>[my, food, stock, is, not, the, only, one, whi...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>me ready to go at supermarket during the outbr...</td>\n",
              "      <td>[me, ready, to, go, at, supermarket, during, t...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25c15d27-82b7-4bc0-84d6-8ce3f2ec0611')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-25c15d27-82b7-4bc0-84d6-8ce3f2ec0611 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-25c15d27-82b7-4bc0-84d6-8ce3f2ec0611');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a5872163-9cd4-40cb-b68f-32889455d51d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a5872163-9cd4-40cb-b68f-32889455d51d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a5872163-9cd4-40cb-b68f-32889455d51d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_clean",
              "summary": "{\n  \"name\": \"df_clean\",\n  \"rows\": 41157,\n  \"fields\": [\n    {\n      \"column\": \"CleanTweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 40916,\n        \"samples\": [\n          \"global giant says consumer spending via its network is considerably down this month the spread of the and associated movement are causing people to shop less even online\",\n          \"sa s largest food retailer is asking people to buy what they need as many consumers are panic buying and stockpiling goods after fears of forces quarantine due to global covid 19 outbreak\",\n          \"if petrol prices drop any further reliance may need to lay off a few lok sabha members\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Positive\",\n          \"Extremely Positive\",\n          \"Extremely Negative\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean_test = preprocess_tweets(df_test)\n",
        "df_clean_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9vLAIrNlKIGp",
        "outputId": "c503ab60-0d2c-4a60-8a87-3a8da373adda"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          CleanTweet  \\\n",
              "0  trending new yorkers encounter empty supermark...   \n",
              "1  when i couldn t find hand sanitizer at fred me...   \n",
              "2  find out how you can protect yourself and love...   \n",
              "3  buying hits city as anxious shoppers stock up ...   \n",
              "4  one week everyone buying baby milk powder the ...   \n",
              "\n",
              "                                              Tokens           Sentiment  \n",
              "0  [trending, new, yorkers, encounter, empty, sup...  Extremely Negative  \n",
              "1  [when, i, couldn, t, find, hand, sanitizer, at...            Positive  \n",
              "2  [find, out, how, you, can, protect, yourself, ...  Extremely Positive  \n",
              "3  [buying, hits, city, as, anxious, shoppers, st...            Negative  \n",
              "4  [one, week, everyone, buying, baby, milk, powd...             Neutral  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8a29f358-f57b-4b0d-94d6-f0e716b2f795\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CleanTweet</th>\n",
              "      <th>Tokens</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>trending new yorkers encounter empty supermark...</td>\n",
              "      <td>[trending, new, yorkers, encounter, empty, sup...</td>\n",
              "      <td>Extremely Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>when i couldn t find hand sanitizer at fred me...</td>\n",
              "      <td>[when, i, couldn, t, find, hand, sanitizer, at...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>find out how you can protect yourself and love...</td>\n",
              "      <td>[find, out, how, you, can, protect, yourself, ...</td>\n",
              "      <td>Extremely Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>buying hits city as anxious shoppers stock up ...</td>\n",
              "      <td>[buying, hits, city, as, anxious, shoppers, st...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>one week everyone buying baby milk powder the ...</td>\n",
              "      <td>[one, week, everyone, buying, baby, milk, powd...</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a29f358-f57b-4b0d-94d6-f0e716b2f795')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8a29f358-f57b-4b0d-94d6-f0e716b2f795 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8a29f358-f57b-4b0d-94d6-f0e716b2f795');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-158c16e6-d0aa-4580-b686-751b48db268f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-158c16e6-d0aa-4580-b686-751b48db268f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-158c16e6-d0aa-4580-b686-751b48db268f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_clean_test",
              "summary": "{\n  \"name\": \"df_clean_test\",\n  \"rows\": 3798,\n  \"fields\": [\n    {\n      \"column\": \"CleanTweet\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3790,\n        \"samples\": [\n          \"update as we continue to monitor the effects of covid 19 on our community we have decided to postpone all tastings in march however we are still open for business don t forget we offer online shopping and delivery services\",\n          \"in tesco s y day noted huge collection 4 food bank fb was relieved to see it even tho i despair fbs are needed been worrying me how ppl on low incomes would stock up on provisions in prep 4 self isolation you need to have a store cupboard\",\n          \"i m not discounting the danger for some while attending a sporting event but tell me why it s ok for me to continue going to work at a grocery store where thousands of customers come and go on a daily basis carrying an unknown amount of sicknesses or the\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Positive\",\n          \"Neutral\",\n          \"Extremely Positive\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "def prepare_data(df, df_test, max_length=50, vocab_size=10000, val_split_ratio=0.1):\n",
        "    \"\"\"\n",
        "    Prepares data for a neural network using separate train/validation and test sets.\n",
        "\n",
        "    This function performs the following steps:\n",
        "    1. Splits the main DataFrame `df` into training and validation sets.\n",
        "    2. Encodes sentiment labels into integers.\n",
        "    3. Builds a vocabulary from the training data ONLY.\n",
        "    4. Processes the external `df_test` using the established vocabulary and label encoding.\n",
        "    5. Converts all token sequences to integer sequences and pads them.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame for training and validation.\n",
        "        df_test (pd.DataFrame): Separate DataFrame for testing.\n",
        "        max_length (int): The fixed length for all sequences.\n",
        "        vocab_size (int): The maximum number of words in the vocabulary.\n",
        "        val_split_ratio (float): The proportion of `df` to be used for validation.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the processed train, val, and test sets,\n",
        "               plus the word and label mapping dictionaries.\n",
        "    \"\"\"\n",
        "    # --- 1. Encode Labels on the main DataFrame ---\n",
        "    unique_labels = df['Sentiment'].unique()\n",
        "    label_to_idx = {label: i for i, label in enumerate(unique_labels)}\n",
        "    encoded_labels = df['Sentiment'].map(label_to_idx).to_numpy()\n",
        "    token_sequences = df['Tokens'].tolist()\n",
        "\n",
        "    # --- 2. Split main DataFrame into Training and Validation ---\n",
        "    num_samples = len(token_sequences)\n",
        "    indices = np.arange(num_samples)\n",
        "    np.random.seed(42) # for reproducibility\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    shuffled_sequences = [token_sequences[i] for i in indices]\n",
        "    shuffled_labels = encoded_labels[indices]\n",
        "\n",
        "    val_split_index = int((1 - val_split_ratio) * num_samples)\n",
        "\n",
        "    train_seqs = shuffled_sequences[:val_split_index]\n",
        "    y_train = shuffled_labels[:val_split_index]\n",
        "\n",
        "    val_seqs = shuffled_sequences[val_split_index:]\n",
        "    y_val = shuffled_labels[val_split_index:]\n",
        "\n",
        "    # --- 3. Build Vocabulary (from training data only) ---\n",
        "    word_counts = Counter(word for seq in train_seqs for word in seq)\n",
        "    most_common_words = [word for word, count in word_counts.most_common(vocab_size - 2)]\n",
        "\n",
        "    word_to_idx = {'<PAD>': 0, '<UNK>': 1}\n",
        "    for i, word in enumerate(most_common_words):\n",
        "        word_to_idx[word] = i + 2\n",
        "\n",
        "    # --- 4. Process the External Test Set ---\n",
        "    # NOTE: Assumes df_test has already been preprocessed to have 'Tokens' and 'Sentiment'\n",
        "    test_seqs = df_test['Tokens'].tolist()\n",
        "    y_test = df_test['Sentiment'].map(label_to_idx).to_numpy()\n",
        "\n",
        "    # --- 5. Encode and Pad all Data Splits ---\n",
        "    def encode_and_pad(sequences, word_map, length):\n",
        "        padded_features = np.zeros((len(sequences), length), dtype=np.int32)\n",
        "        for i, seq in enumerate(sequences):\n",
        "            for j, word in enumerate(seq):\n",
        "                if j >= length: # Truncate if sequence is too long\n",
        "                    break\n",
        "                # Default to <UNK> token's index (1) if word is not in vocab\n",
        "                padded_features[i, j] = word_map.get(word, 1)\n",
        "        return padded_features\n",
        "\n",
        "    X_train = encode_and_pad(train_seqs, word_to_idx, max_length)\n",
        "    X_val = encode_and_pad(val_seqs, word_to_idx, max_length)\n",
        "    X_test = encode_and_pad(test_seqs, word_to_idx, max_length)\n",
        "\n",
        "    return (X_train, y_train), (X_val, y_val), (X_test, y_test), word_to_idx, label_to_idx"
      ],
      "metadata": {
        "id": "_Q6pP-8wxjq8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameters\n",
        "MAX_SEQ_LENGTH = 50\n",
        "VOCAB_SIZE = 10000\n",
        "\n",
        "# Call the function to get your final, model-ready data\n",
        "(X_train, y_train), (X_val, y_val), (X_test, y_test), word_to_idx, label_to_idx = prepare_data(\n",
        "    df_clean,df_clean_test,\n",
        "    max_length=MAX_SEQ_LENGTH,\n",
        "    vocab_size=VOCAB_SIZE\n",
        ")\n",
        "\n",
        "# You can now check the shapes and content\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"-\" * 30)\n",
        "print(\"Example sequence (integers):\", X_train[0])\n",
        "print(\"Corresponding label (integer):\", y_train[0])\n",
        "print(\"-\" * 30)\n",
        "print(\"Vocabulary size:\", len(word_to_idx))\n",
        "print(\"Label mapping:\", label_to_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4d4UpmA0NXG",
        "outputId": "17018c35-29a7-4572-99ac-6378d72a503c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: (37041, 50)\n",
            "Shape of y_train: (37041,)\n",
            "------------------------------\n",
            "Example sequence (integers): [ 300    2   69  137   38   30  144  708 5650   31   11  229  723   62\n",
            "    2  134  270   18    8  403   23 1564   11  696    3 2021    7   81\n",
            " 2427    5    2  159  118    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0]\n",
            "Corresponding label (integer): 0\n",
            "------------------------------\n",
            "Vocabulary size: 10000\n",
            "Label mapping: {'Neutral': 0, 'Positive': 1, 'Extremely Negative': 2, 'Negative': 3, 'Extremely Positive': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ywtQZo_T0tSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mini-Batches"
      ],
      "metadata": {
        "id": "fxPhOjn-38rN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_mini_batches(X, y, batch_size=64, shuffle=True):\n",
        "    \"\"\"\n",
        "    Creates a generator of mini-batches from the input data.\n",
        "\n",
        "    Args:\n",
        "        X (np.ndarray): Input data of shape (num_samples, seq_length).\n",
        "        y (np.ndarray): Labels of shape (num_samples,).\n",
        "        batch_size (int): The size of each mini-batch.\n",
        "        shuffle (bool): If True, shuffles the data at the start of each epoch.\n",
        "\n",
        "    Yields:\n",
        "        tuple: A tuple containing a mini-batch of data and its corresponding labels.\n",
        "    \"\"\"\n",
        "    num_samples = X.shape[0]\n",
        "\n",
        "    # Create a permutation of indices\n",
        "    indices = np.arange(num_samples)\n",
        "    if shuffle:\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "    # Yield batches one by one\n",
        "    for start_idx in range(0, num_samples, batch_size):\n",
        "        end_idx = min(start_idx + batch_size, num_samples)\n",
        "        batch_indices = indices[start_idx:end_idx]\n",
        "\n",
        "        yield X[batch_indices], y[batch_indices]"
      ],
      "metadata": {
        "id": "lF2gH3Aw3-YU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define your batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# 2. Create the mini-batch generator using your actual training data\n",
        "train_mini_batch_generator = create_mini_batches(X_train, y_train, batch_size=BATCH_SIZE)\n",
        "\n",
        "# 3. (Optional) Loop through it to see the batches being created\n",
        "print(f\"Creating mini-batches of size {BATCH_SIZE} from training data...\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "for i, (mini_batch_X, mini_batch_y) in enumerate(train_mini_batch_generator):\n",
        "    # In a real training loop, you would feed this batch into your model\n",
        "    if i < 3: # Let's just print the first 3 batches to check\n",
        "      print(f\"Mini-batch {i+1}:\")\n",
        "      print(f\"  X shape: {mini_batch_X.shape}\")\n",
        "      print(f\"  y shape: {mini_batch_y.shape}\")\n",
        "\n",
        "print(\"\\n...\")\n",
        "print(\"Generator is ready for the training loop.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQHNDTxc3-5Q",
        "outputId": "afb2d74a-3b8c-4ce2-8a48-4fec50c8a0e4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating mini-batches of size 64 from training data...\n",
            "------------------------------\n",
            "Mini-batch 1:\n",
            "  X shape: (64, 50)\n",
            "  y shape: (64,)\n",
            "Mini-batch 2:\n",
            "  X shape: (64, 50)\n",
            "  y shape: (64,)\n",
            "Mini-batch 3:\n",
            "  X shape: (64, 50)\n",
            "  y shape: (64,)\n",
            "\n",
            "...\n",
            "Generator is ready for the training loop.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F-XrGZ5N4R0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "7HfX3XVu6i93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics(y_true, y_pred, num_classes):\n",
        "    # --- Calculate Accuracy ---\n",
        "    accuracy = np.mean(y_true == y_pred)\n",
        "\n",
        "    # --- Calculate Macro F1-Score ---\n",
        "    f1_per_class = []\n",
        "    for c in range(num_classes):\n",
        "        # True Positives, False Positives, False Negatives\n",
        "        tp = np.sum((y_pred == c) & (y_true == c))\n",
        "        fp = np.sum((y_pred == c) & (y_true != c))\n",
        "        fn = np.sum((y_pred != c) & (y_true == c))\n",
        "\n",
        "        # Precision and Recall for the current class\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "\n",
        "        # F1-Score for the current class\n",
        "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "        f1_per_class.append(f1)\n",
        "\n",
        "    macro_f1 = np.mean(f1_per_class)\n",
        "\n",
        "    return accuracy, macro_f1"
      ],
      "metadata": {
        "id": "5XcWZNoj6mJU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model, word_to_idx, label_to_idx, filepath):\n",
        "    \"\"\"\n",
        "    Saves the model parameters and mappings to a compressed .npz file.\n",
        "\n",
        "    Args:\n",
        "        model (RNN): The trained RNN model instance.\n",
        "        word_to_idx (dict): The vocabulary mapping.\n",
        "        label_to_idx (dict): The class label mapping.\n",
        "        filepath (str): The path to save the file (e.g., 'my_model.npz').\n",
        "    \"\"\"\n",
        "    # np.savez_compressed can save dictionaries if they are passed as keyword arguments.\n",
        "    # We use **model.params to unpack the parameters dictionary.\n",
        "    np.savez_compressed(\n",
        "        filepath,\n",
        "        **model.params,\n",
        "        word_to_idx=word_to_idx,\n",
        "        label_to_idx=label_to_idx\n",
        "    )\n",
        "    print(f\"Model saved to {filepath}\")"
      ],
      "metadata": {
        "id": "KvaXLQwD6mrE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models"
      ],
      "metadata": {
        "id": "tBNrfHt36pPK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN"
      ],
      "metadata": {
        "id": "Ciz5oKX56zoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "class RNN:\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
        "        \"\"\"Initializes the RNN with Xavier (Glorot) Initialization.\"\"\"\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        # --- 1. Optimized Parameter Initialization (Xavier/Glorot) ---\n",
        "        # This method helps maintain signal variance and combats vanishing/exploding gradients.\n",
        "        self.params = {}\n",
        "\n",
        "        # Embedding Matrix\n",
        "        limit_E = np.sqrt(6.0 / (vocab_size + embedding_dim))\n",
        "        self.params['E'] = np.random.uniform(-limit_E, limit_E, (vocab_size, embedding_dim))\n",
        "\n",
        "        # Input to Hidden Weights\n",
        "        limit_Wxh = np.sqrt(6.0 / (embedding_dim + hidden_dim))\n",
        "        self.params['W_xh'] = np.random.uniform(-limit_Wxh, limit_Wxh, (embedding_dim, hidden_dim))\n",
        "\n",
        "        # Hidden to Hidden Weights\n",
        "        limit_Whh = np.sqrt(6.0 / (hidden_dim + hidden_dim))\n",
        "        self.params['W_hh'] = np.random.uniform(-limit_Whh, limit_Whh, (hidden_dim, hidden_dim))\n",
        "\n",
        "        # Hidden bias (initialized to zeros)\n",
        "        self.params['b_h'] = np.zeros((1, hidden_dim))\n",
        "\n",
        "        # Hidden to Output Weights\n",
        "        limit_Why = np.sqrt(6.0 / (hidden_dim + output_dim))\n",
        "        self.params['W_hy'] = np.random.uniform(-limit_Why, limit_Why, (hidden_dim, output_dim))\n",
        "\n",
        "        # Output bias (initialized to zeros)\n",
        "        self.params['b_y'] = np.zeros((1, output_dim))\n",
        "\n",
        "        # 2. Initialize Adam Optimizer State\n",
        "        self.adam_m = {k: np.zeros_like(v) for k, v in self.params.items()}\n",
        "        self.adam_v = {k: np.zeros_like(v) for k, v in self.params.items()}\n",
        "        self.adam_t = 0 # Timestep counter\n",
        "\n",
        "    def _softmax(self, z):\n",
        "        \"\"\"Computes softmax probabilities.\"\"\"\n",
        "        exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
        "        return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
        "\n",
        "    def forward(self, X_batch):\n",
        "        \"\"\"Performs the forward pass for a batch of sequences.\"\"\"\n",
        "        E, W_xh, W_hh, b_h, W_hy, b_y = (self.params[k] for k in\n",
        "                                        ('E', 'W_xh', 'W_hh', 'b_h', 'W_hy', 'b_y'))\n",
        "        batch_size, seq_length = X_batch.shape\n",
        "\n",
        "        h_prev = np.zeros((batch_size, self.hidden_dim))\n",
        "        cache = {'h': {0: h_prev}, 'x_embedded': {}, 'X_batch': X_batch}\n",
        "\n",
        "        for t in range(seq_length):\n",
        "            word_indices = X_batch[:, t]\n",
        "            x_t = E[word_indices]\n",
        "            h_next = np.tanh(x_t @ W_xh + h_prev @ W_hh + b_h)\n",
        "\n",
        "            cache['x_embedded'][t] = x_t\n",
        "            cache['h'][t + 1] = h_next\n",
        "            h_prev = h_next\n",
        "\n",
        "        logits = h_prev @ W_hy + b_y\n",
        "        probs = self._softmax(logits)\n",
        "        cache['probs'] = probs\n",
        "        return probs, cache\n",
        "\n",
        "    def compute_loss(self, probs, y_batch):\n",
        "        \"\"\"Computes cross-entropy loss.\"\"\"\n",
        "        batch_size = y_batch.shape[0]\n",
        "        log_probs = -np.log(probs[np.arange(batch_size), y_batch] + 1e-9) # add epsilon for stability\n",
        "        loss = np.sum(log_probs) / batch_size\n",
        "        return loss\n",
        "\n",
        "    def backward(self, y_batch, cache):\n",
        "        \"\"\"Performs backpropagation through time (BPTT).\"\"\"\n",
        "        E, W_xh, W_hh, W_hy = (self.params[k] for k in ('E', 'W_xh', 'W_hh', 'W_hy'))\n",
        "        probs, h, x_embedded, X_batch = (cache[k] for k in ('probs', 'h', 'x_embedded', 'X_batch'))\n",
        "        batch_size, seq_length = X_batch.shape\n",
        "\n",
        "        grads = {k: np.zeros_like(v) for k, v in self.params.items()}\n",
        "\n",
        "        d_logits = np.copy(probs)\n",
        "        d_logits[np.arange(batch_size), y_batch] -= 1\n",
        "        d_logits /= batch_size\n",
        "\n",
        "        h_final = h[len(h) - 1]\n",
        "        grads['W_hy'] = h_final.T @ d_logits\n",
        "        grads['b_y'] = np.sum(d_logits, axis=0, keepdims=True)\n",
        "        d_h = d_logits @ W_hy.T\n",
        "\n",
        "        for t in reversed(range(seq_length)):\n",
        "            d_tanh = (1 - h[t + 1]**2) * d_h\n",
        "            grads['b_h'] += np.sum(d_tanh, axis=0, keepdims=True)\n",
        "            grads['W_hh'] += h[t].T @ d_tanh\n",
        "            grads['W_xh'] += x_embedded[t].T @ d_tanh\n",
        "            d_h = d_tanh @ W_hh.T\n",
        "            d_E_t = d_tanh @ W_xh.T\n",
        "            np.add.at(grads['E'], X_batch[:, t], d_E_t)\n",
        "\n",
        "        # Clip gradients to prevent explosion\n",
        "        for key in grads:\n",
        "            np.clip(grads[key], -5, 5, out=grads[key])\n",
        "\n",
        "        return grads\n",
        "\n",
        "    def update_params_with_adam(self, grads, learning_rate, beta1, beta2, epsilon=1e-8):\n",
        "        \"\"\"Updates parameters using the Adam optimizer.\"\"\"\n",
        "        self.adam_t += 1 # Increment timestep\n",
        "\n",
        "        for key in self.params:\n",
        "            self.adam_m[key] = beta1 * self.adam_m[key] + (1 - beta1) * grads[key]\n",
        "            self.adam_v[key] = beta2 * self.adam_v[key] + (1 - beta2) * (grads[key] ** 2)\n",
        "            m_hat = self.adam_m[key] / (1 - beta1 ** self.adam_t)\n",
        "            v_hat = self.adam_v[key] / (1 - beta2 ** self.adam_t)\n",
        "            self.params[key] -= learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Makes predictions for a given input X.\"\"\"\n",
        "        probs, _ = self.forward(X)\n",
        "        return np.argmax(probs, axis=1)"
      ],
      "metadata": {
        "id": "oEmLuwHb6rb3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "9g6uzEUTTzKr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "class LSTM:\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
        "        \"\"\"Initializes the LSTM model with Xavier Initialization.\"\"\"\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        self.params = {}\n",
        "        combined_dim = embedding_dim + hidden_dim\n",
        "\n",
        "        limit_E = np.sqrt(6.0 / (vocab_size + embedding_dim))\n",
        "        self.params['E'] = np.random.uniform(-limit_E, limit_E, (vocab_size, embedding_dim))\n",
        "\n",
        "        limit_gates = np.sqrt(6.0 / (combined_dim + 4 * hidden_dim))\n",
        "        self.params['W_gates'] = np.random.uniform(-limit_gates, limit_gates, (combined_dim, 4 * hidden_dim))\n",
        "        self.params['b_gates'] = np.zeros((1, 4 * hidden_dim))\n",
        "\n",
        "        limit_Why = np.sqrt(6.0 / (hidden_dim + output_dim))\n",
        "        self.params['W_hy'] = np.random.uniform(-limit_Why, limit_Why, (hidden_dim, output_dim))\n",
        "        self.params['b_y'] = np.zeros((1, output_dim))\n",
        "\n",
        "        self.adam_m = {k: np.zeros_like(v) for k, v in self.params.items()}\n",
        "        self.adam_v = {k: np.zeros_like(v) for k, v in self.params.items()}\n",
        "        self.adam_t = 0\n",
        "\n",
        "    def _sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "\n",
        "    def _softmax(self, z):\n",
        "        exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
        "        return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
        "\n",
        "    def forward(self, X_batch):\n",
        "        \"\"\"Performs the forward pass for the LSTM.\"\"\"\n",
        "        E, W_gates, b_gates, W_hy, b_y = (self.params[k] for k in\n",
        "                                          ('E', 'W_gates', 'b_gates', 'W_hy', 'b_y'))\n",
        "        batch_size, seq_length = X_batch.shape\n",
        "        h_dim = self.hidden_dim\n",
        "\n",
        "        h_prev = np.zeros((batch_size, h_dim))\n",
        "        c_prev = np.zeros((batch_size, h_dim))\n",
        "\n",
        "        cache = {'X_batch': X_batch, 'h': {}, 'c': {}, 'gates': {}}\n",
        "        cache['h'][-1], cache['c'][-1] = h_prev, c_prev\n",
        "\n",
        "        for t in range(seq_length):\n",
        "            word_indices = X_batch[:, t]\n",
        "            x_t = E[word_indices]\n",
        "\n",
        "            combined_input = np.hstack((h_prev, x_t))\n",
        "            gates_raw = combined_input @ W_gates + b_gates\n",
        "\n",
        "            f_raw, i_raw, c_tilde_raw, o_raw = np.split(gates_raw, 4, axis=1)\n",
        "\n",
        "            f = self._sigmoid(f_raw)\n",
        "            i = self._sigmoid(i_raw)\n",
        "            c_tilde = np.tanh(c_tilde_raw)\n",
        "            o = self._sigmoid(o_raw)\n",
        "\n",
        "            c_next = f * c_prev + i * c_tilde\n",
        "            h_next = o * np.tanh(c_next)\n",
        "\n",
        "            cache['gates'][t] = {'f': f, 'i': i, 'o': o, 'c_tilde': c_tilde, 'combined': combined_input}\n",
        "            cache['h'][t], cache['c'][t] = h_next, c_next\n",
        "\n",
        "            h_prev, c_prev = h_next, c_next\n",
        "\n",
        "        # --- *** FIX 1: Store the final hidden state *** ---\n",
        "        h_final = h_prev\n",
        "        cache['h_final'] = h_final\n",
        "        # --- End of Fix ---\n",
        "\n",
        "        logits = h_final @ W_hy + b_y\n",
        "        probs = self._softmax(logits)\n",
        "        cache['probs'] = probs\n",
        "\n",
        "        return probs, cache\n",
        "\n",
        "    def compute_loss(self, probs, y_batch):\n",
        "        batch_size = y_batch.shape[0]\n",
        "        log_probs = -np.log(probs[np.arange(batch_size), y_batch] + 1e-9)\n",
        "        return np.sum(log_probs) / batch_size\n",
        "\n",
        "    def backward(self, y_batch, cache):\n",
        "        \"\"\"Performs backpropagation for the LSTM.\"\"\"\n",
        "        W_gates, W_hy = self.params['W_gates'], self.params['W_hy']\n",
        "        probs, X_batch = cache['probs'], cache['X_batch']\n",
        "        batch_size, seq_length = X_batch.shape\n",
        "        e_dim, h_dim = self.embedding_dim, self.hidden_dim\n",
        "\n",
        "        grads = {k: np.zeros_like(v) for k, v in self.params.items()}\n",
        "        dh_next = np.zeros((batch_size, h_dim))\n",
        "        dc_next = np.zeros((batch_size, h_dim))\n",
        "\n",
        "        d_logits = np.copy(probs)\n",
        "        d_logits[np.arange(batch_size), y_batch] -= 1\n",
        "        d_logits /= batch_size\n",
        "\n",
        "        # --- *** FIX 2: Retrieve h_final correctly *** ---\n",
        "        h_final = cache['h_final']\n",
        "        # --- End of Fix ---\n",
        "\n",
        "        grads['W_hy'] = h_final.T @ d_logits\n",
        "        grads['b_y'] = np.sum(d_logits, axis=0, keepdims=True)\n",
        "        dh_next = d_logits @ W_hy.T\n",
        "\n",
        "        for t in reversed(range(seq_length)):\n",
        "            gates = cache['gates'][t]\n",
        "            c_prev = cache['c'][t-1]\n",
        "            c_curr = cache['c'][t]\n",
        "            combined = gates['combined']\n",
        "\n",
        "            dh = dh_next\n",
        "            do = dh * np.tanh(c_curr)\n",
        "            do_raw = do * gates['o'] * (1 - gates['o'])\n",
        "\n",
        "            dc = dc_next + dh * gates['o'] * (1 - np.tanh(c_curr)**2)\n",
        "\n",
        "            df = dc * c_prev\n",
        "            df_raw = df * gates['f'] * (1 - gates['f'])\n",
        "\n",
        "            di = dc * gates['c_tilde']\n",
        "            di_raw = di * gates['i'] * (1 - gates['i'])\n",
        "\n",
        "            dc_tilde = dc * gates['i']\n",
        "            dc_tilde_raw = dc_tilde * (1 - gates['c_tilde']**2)\n",
        "\n",
        "            d_gates_raw = np.hstack((df_raw, di_raw, dc_tilde_raw, do_raw))\n",
        "\n",
        "            grads['W_gates'] += combined.T @ d_gates_raw\n",
        "            grads['b_gates'] += np.sum(d_gates_raw, axis=0, keepdims=True)\n",
        "\n",
        "            d_combined = d_gates_raw @ W_gates.T\n",
        "\n",
        "            dh_next = d_combined[:, :h_dim]\n",
        "            dc_next = dc * gates['f']\n",
        "\n",
        "            dx_t = d_combined[:, h_dim:]\n",
        "            np.add.at(grads['E'], X_batch[:, t], dx_t)\n",
        "\n",
        "        for key in grads:\n",
        "            np.clip(grads[key], -5, 5, out=grads[key])\n",
        "\n",
        "        return grads\n",
        "\n",
        "    def update_params_with_adam(self, grads, learning_rate, beta1, beta2, epsilon=1e-8):\n",
        "        self.adam_t += 1\n",
        "        for key in self.params:\n",
        "            self.adam_m[key] = beta1 * self.adam_m[key] + (1 - beta1) * grads[key]\n",
        "            self.adam_v[key] = beta2 * self.adam_v[key] + (1 - beta2) * (grads[key] ** 2)\n",
        "            m_hat = self.adam_m[key] / (1 - beta1 ** self.adam_t)\n",
        "            v_hat = self.adam_v[key] / (1 - beta2 ** self.adam_t)\n",
        "            self.params[key] -= learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n",
        "\n",
        "    def predict(self, X):\n",
        "        probs, _ = self.forward(X)\n",
        "        return np.argmax(probs, axis=1)"
      ],
      "metadata": {
        "id": "S7IEN4aT6xJw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tranformer"
      ],
      "metadata": {
        "id": "fnhWAVwmmSkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "# ===================================================================\n",
        "# SECTION 1: HELPER FUNCTIONS\n",
        "# ===================================================================\n",
        "\n",
        "def positional_encoding(seq_length, embedding_dim):\n",
        "    \"\"\"Generates the positional encoding matrix.\"\"\"\n",
        "    pos = np.arange(seq_length)[:, np.newaxis]\n",
        "    i = np.arange(embedding_dim)[np.newaxis, :]\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(embedding_dim))\n",
        "    angle_rads = pos * angle_rates\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "    return pos_encoding.astype(np.float32)\n",
        "\n",
        "def create_mini_batches(X, y, batch_size=64, shuffle=True):\n",
        "    \"\"\"Creates a generator of mini-batches.\"\"\"\n",
        "    num_samples = X.shape[0]\n",
        "    indices = np.arange(num_samples)\n",
        "    if shuffle:\n",
        "        np.random.shuffle(indices)\n",
        "    for start_idx in range(0, num_samples, batch_size):\n",
        "        end_idx = min(start_idx + batch_size, num_samples)\n",
        "        batch_indices = indices[start_idx:end_idx]\n",
        "        yield X[batch_indices], y[batch_indices]\n",
        "\n",
        "def calculate_metrics(y_true, y_pred, num_classes):\n",
        "    \"\"\"Calculates accuracy and macro F1-score.\"\"\"\n",
        "    accuracy = np.mean(y_true == y_pred)\n",
        "    f1_per_class = []\n",
        "    for c in range(num_classes):\n",
        "        tp = np.sum((y_pred == c) & (y_true == c))\n",
        "        fp = np.sum((y_pred == c) & (y_true != c))\n",
        "        fn = np.sum((y_pred != c) & (y_true == c))\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "        f1_per_class.append(f1)\n",
        "    macro_f1 = np.mean(f1_per_class)\n",
        "    return accuracy, macro_f1\n",
        "\n",
        "# ===================================================================\n",
        "# SECTION 2: TRANSFORMER ENCODER CLASS\n",
        "# ===================================================================\n",
        "\n",
        "class TransformerEncoder:\n",
        "    def __init__(self, vocab_size, max_len, embedding_dim, num_heads, ff_hidden_dim, num_blocks, output_dim):\n",
        "        self.params = {}\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.num_blocks = num_blocks\n",
        "        self.output_dim = output_dim  # <-- *** ADD THIS LINE ***\n",
        "\n",
        "        self.params['E'] = np.random.randn(vocab_size, embedding_dim) * 0.01\n",
        "        self.pos_encoding = positional_encoding(max_len, embedding_dim)\n",
        "\n",
        "        self.params['blocks'] = {}\n",
        "        for i in range(num_blocks):\n",
        "            block = {\n",
        "                'W_qkv': np.random.randn(embedding_dim, 3 * embedding_dim) * 0.01,\n",
        "                'W_o': np.random.randn(embedding_dim, embedding_dim) * 0.01,\n",
        "                'ln1_gamma': np.ones((1, 1, embedding_dim)), 'ln1_beta': np.zeros((1, 1, embedding_dim)),\n",
        "                'ln2_gamma': np.ones((1, 1, embedding_dim)), 'ln2_beta': np.zeros((1, 1, embedding_dim)),\n",
        "                'W1': np.random.randn(embedding_dim, ff_hidden_dim) * 0.01, 'b1': np.zeros((1, ff_hidden_dim)),\n",
        "                'W2': np.random.randn(ff_hidden_dim, embedding_dim) * 0.01, 'b2': np.zeros((1, embedding_dim))\n",
        "            }\n",
        "            self.params['blocks'][i] = block\n",
        "\n",
        "        self.params['W_out'] = np.random.randn(embedding_dim, output_dim) * 0.01\n",
        "        self.params['b_out'] = np.zeros((1, output_dim))\n",
        "        self._initialize_adam()\n",
        "\n",
        "        self.params['W_out'] = np.random.randn(embedding_dim, output_dim) * 0.01\n",
        "        self.params['b_out'] = np.zeros((1, output_dim))\n",
        "        self._initialize_adam()\n",
        "\n",
        "        self.params['W_out'] = np.random.randn(embedding_dim, output_dim) * 0.01\n",
        "        self.params['b_out'] = np.zeros((1, output_dim))\n",
        "        self._initialize_adam()\n",
        "\n",
        "    def _initialize_adam(self):\n",
        "        self.adam_m = {'E': np.zeros_like(self.params['E']), 'W_out': np.zeros_like(self.params['W_out']), 'b_out': np.zeros_like(self.params['b_out']), 'blocks': {}}\n",
        "        self.adam_v = {'E': np.zeros_like(self.params['E']), 'W_out': np.zeros_like(self.params['W_out']), 'b_out': np.zeros_like(self.params['b_out']), 'blocks': {}}\n",
        "        for i in range(self.num_blocks):\n",
        "            self.adam_m['blocks'][i] = {k: np.zeros_like(v) for k, v in self.params['blocks'][i].items()}\n",
        "            self.adam_v['blocks'][i] = {k: np.zeros_like(v) for k, v in self.params['blocks'][i].items()}\n",
        "        self.adam_t = 0\n",
        "\n",
        "    def _softmax(self, z):\n",
        "        exp_z = np.exp(z - np.max(z, axis=-1, keepdims=True))\n",
        "        return exp_z / np.sum(exp_z, axis=-1, keepdims=True)\n",
        "\n",
        "    def _layer_norm_forward(self, x, gamma, beta, epsilon=1e-5):\n",
        "        mean = np.mean(x, axis=-1, keepdims=True)\n",
        "        variance = np.var(x, axis=-1, keepdims=True)\n",
        "        x_normalized = (x - mean) / np.sqrt(variance + epsilon)\n",
        "        out = gamma * x_normalized + beta\n",
        "        cache = (x, x_normalized, mean, variance, gamma, epsilon)\n",
        "        return out, cache\n",
        "\n",
        "    def _multi_head_attention_forward(self, x, W_qkv, W_o):\n",
        "        batch_size, seq_len, d_model = x.shape\n",
        "        d_head = d_model // self.num_heads\n",
        "        qkv = x @ W_qkv\n",
        "        q, k, v = np.split(qkv, 3, axis=-1)\n",
        "        q = q.reshape(batch_size, seq_len, self.num_heads, d_head).transpose(0, 2, 1, 3)\n",
        "        k = k.reshape(batch_size, seq_len, self.num_heads, d_head).transpose(0, 2, 1, 3)\n",
        "        v = v.reshape(batch_size, seq_len, self.num_heads, d_head).transpose(0, 2, 1, 3)\n",
        "        scores = (q @ k.transpose(0, 1, 3, 2)) / np.sqrt(d_head)\n",
        "        weights = self._softmax(scores)\n",
        "        attention = weights @ v\n",
        "        attention = attention.transpose(0, 2, 1, 3).reshape(batch_size, seq_len, d_model)\n",
        "        out = attention @ W_o\n",
        "        cache = (x, q, k, v, weights, attention, W_qkv, W_o)\n",
        "        return out, cache\n",
        "\n",
        "    def forward(self, X_batch):\n",
        "        batch_size, seq_len = X_batch.shape\n",
        "        cache = {'X_batch': X_batch, 'blocks': {}}\n",
        "        x = self.params['E'][X_batch] + self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        for i in range(self.num_blocks):\n",
        "            block_params = self.params['blocks'][i]\n",
        "            ln1_in = x\n",
        "            mha_out, mha_cache = self._multi_head_attention_forward(ln1_in, block_params['W_qkv'], block_params['W_o'])\n",
        "            add_norm1_in = ln1_in + mha_out\n",
        "            add_norm1_out, ln1_cache = self._layer_norm_forward(add_norm1_in, block_params['ln1_gamma'], block_params['ln1_beta'])\n",
        "\n",
        "            ln2_in = add_norm1_out\n",
        "            ffn_hidden = np.maximum(0, ln2_in @ block_params['W1'] + block_params['b1'])\n",
        "            ffn_out = ffn_hidden @ block_params['W2'] + block_params['b2']\n",
        "            add_norm2_in = ln2_in + ffn_out\n",
        "            add_norm2_out, ln2_cache = self._layer_norm_forward(add_norm2_in, block_params['ln2_gamma'], block_params['ln2_beta'])\n",
        "\n",
        "            x = add_norm2_out\n",
        "            cache['blocks'][i] = {'mha_cache': mha_cache, 'ln1_cache': ln1_cache, 'ln2_cache': ln2_cache, 'ffn_hidden': ffn_hidden, 'ln1_in': ln1_in, 'ln2_in': ln2_in}\n",
        "\n",
        "        pooled_out = np.mean(x, axis=1)\n",
        "        logits = pooled_out @ self.params['W_out'] + self.params['b_out']\n",
        "        probs = self._softmax(logits)\n",
        "        cache.update({'final_x': x, 'pooled_out': pooled_out, 'probs': probs})\n",
        "        return probs, cache\n",
        "\n",
        "    def _layer_norm_backward(self, d_out, cache):\n",
        "        x, x_norm, mean, var, gamma, eps = cache\n",
        "        N, D = x.shape[0]*x.shape[1], x.shape[2]\n",
        "        d_x_norm = d_out * gamma\n",
        "        d_var = np.sum(d_x_norm * (x - mean) * -0.5 * (var + eps)**(-1.5), axis=-1, keepdims=True)\n",
        "        d_mean = np.sum(d_x_norm * -1 / np.sqrt(var + eps), axis=-1, keepdims=True) + d_var * np.sum(-2 * (x - mean), axis=-1, keepdims=True) / D\n",
        "        d_x = d_x_norm / np.sqrt(var + eps) + d_var * 2 * (x - mean) / D + d_mean / D\n",
        "        d_gamma = np.sum(d_out * x_norm, axis=(0, 1), keepdims=True)\n",
        "        d_beta = np.sum(d_out, axis=(0, 1), keepdims=True)\n",
        "        return d_x, d_gamma, d_beta\n",
        "\n",
        "    def _multi_head_attention_backward(self, d_out, cache):\n",
        "        x, q, k, v, weights, attention, W_qkv, W_o = cache\n",
        "        batch_size, seq_len, d_model = x.shape\n",
        "        d_head = d_model // self.num_heads\n",
        "        d_attention = d_out @ W_o.T\n",
        "        d_W_o = attention.reshape(batch_size * seq_len, d_model).T @ d_out.reshape(batch_size * seq_len, d_model)\n",
        "        d_attention = d_attention.reshape(batch_size, seq_len, self.num_heads, d_head).transpose(0, 2, 1, 3)\n",
        "        d_weights = d_attention @ v.transpose(0, 1, 3, 2)\n",
        "        d_v = weights.transpose(0, 1, 3, 2) @ d_attention\n",
        "        d_scores = weights * (d_weights - np.sum(d_weights * weights, axis=-1, keepdims=True))\n",
        "        d_q = d_scores @ k\n",
        "        d_k = d_scores.transpose(0, 1, 3, 2) @ q\n",
        "        d_q /= np.sqrt(d_head)\n",
        "        d_k /= np.sqrt(d_head)\n",
        "        d_q = d_q.transpose(0, 2, 1, 3).reshape(batch_size, seq_len, d_model)\n",
        "        d_k = d_k.transpose(0, 2, 1, 3).reshape(batch_size, seq_len, d_model)\n",
        "        d_v = d_v.transpose(0, 2, 1, 3).reshape(batch_size, seq_len, d_model)\n",
        "        d_qkv = np.concatenate([d_q, d_k, d_v], axis=-1)\n",
        "        d_W_qkv = x.reshape(batch_size * seq_len, d_model).T @ d_qkv.reshape(batch_size * seq_len, 3 * d_model)\n",
        "        d_x = d_qkv @ W_qkv.T\n",
        "        return d_x, d_W_qkv, d_W_o\n",
        "\n",
        "    def backward(self, y_batch, cache):\n",
        "        grads = {k: np.zeros_like(v) if isinstance(v, np.ndarray) else {} for k, v in self.params.items()}\n",
        "        for i in range(self.num_blocks):\n",
        "             grads['blocks'][i] = {k: np.zeros_like(v) for k, v in self.params['blocks'][i].items()}\n",
        "        probs, X_batch, final_x, pooled_out = cache['probs'], cache['X_batch'], cache['final_x'], cache['pooled_out']\n",
        "        batch_size, seq_len = X_batch.shape\n",
        "\n",
        "        d_logits = (probs - np.eye(self.output_dim)[y_batch]) / batch_size\n",
        "        grads['W_out'] = pooled_out.T @ d_logits\n",
        "        grads['b_out'] = np.sum(d_logits, axis=0)\n",
        "\n",
        "        d_pooled = d_logits @ self.params['W_out'].T\n",
        "        d_x = np.tile(d_pooled[:, np.newaxis, :], (1, seq_len, 1)) / seq_len\n",
        "\n",
        "        for i in reversed(range(self.num_blocks)):\n",
        "            block_params = self.params['blocks'][i]\n",
        "            block_cache = cache['blocks'][i]\n",
        "\n",
        "            d_add_norm2_in, d_ln2_gamma, d_ln2_beta = self._layer_norm_backward(d_x, block_cache['ln2_cache'])\n",
        "            grads['blocks'][i]['ln2_gamma'] += d_ln2_gamma\n",
        "            grads['blocks'][i]['ln2_beta'] += d_ln2_beta\n",
        "\n",
        "            d_ln2_in = d_add_norm2_in\n",
        "            d_ffn_out = d_add_norm2_in\n",
        "\n",
        "            d_ffn_hidden = d_ffn_out @ block_params['W2'].T\n",
        "            grads['blocks'][i]['W2'] += block_cache['ffn_hidden'].reshape(-1, block_cache['ffn_hidden'].shape[-1]).T @ d_ffn_out.reshape(-1, d_ffn_out.shape[-1])\n",
        "            grads['blocks'][i]['b2'] += np.sum(d_ffn_out, axis=(0, 1))\n",
        "\n",
        "            d_ffn_hidden[block_cache['ffn_hidden'] <= 0] = 0\n",
        "\n",
        "            d_add_norm1_out = d_ffn_hidden @ block_params['W1'].T\n",
        "            grads['blocks'][i]['W1'] += block_cache['ln2_in'].reshape(-1, block_cache['ln2_in'].shape[-1]).T @ d_ffn_hidden.reshape(-1, d_ffn_hidden.shape[-1])\n",
        "            grads['blocks'][i]['b1'] += np.sum(d_ffn_hidden, axis=(0, 1))\n",
        "\n",
        "            d_x = d_ln2_in + d_add_norm1_out\n",
        "\n",
        "            d_add_norm1_in, d_ln1_gamma, d_ln1_beta = self._layer_norm_backward(d_x, block_cache['ln1_cache'])\n",
        "            grads['blocks'][i]['ln1_gamma'] += d_ln1_gamma\n",
        "            grads['blocks'][i]['ln1_beta'] += d_ln1_beta\n",
        "\n",
        "            d_ln1_in = d_add_norm1_in\n",
        "            d_mha_out = d_add_norm1_in\n",
        "\n",
        "            d_x_mha, d_W_qkv, d_W_o = self._multi_head_attention_backward(d_mha_out, block_cache['mha_cache'])\n",
        "            grads['blocks'][i]['W_qkv'] += d_W_qkv\n",
        "            grads['blocks'][i]['W_o'] += d_W_o\n",
        "\n",
        "            d_x = d_ln1_in + d_x_mha\n",
        "\n",
        "        d_E = d_x\n",
        "        np.add.at(grads['E'], X_batch, d_E)\n",
        "        return grads\n",
        "\n",
        "    def compute_loss(self, probs, y_batch):\n",
        "        batch_size = y_batch.shape[0]\n",
        "        return -np.sum(np.log(probs[np.arange(batch_size), y_batch] + 1e-9)) / batch_size\n",
        "\n",
        "    def update_params_with_adam(self, grads, learning_rate, beta1, beta2, epsilon=1e-8):\n",
        "        self.adam_t += 1\n",
        "        for p_key in ['E', 'W_out', 'b_out']:\n",
        "            self._adam_update(p_key, grads[p_key], learning_rate, beta1, beta2, epsilon)\n",
        "        for i in range(self.num_blocks):\n",
        "            for key in self.params['blocks'][i]:\n",
        "                self._adam_update(('blocks', i, key), grads['blocks'][i][key], learning_rate, beta1, beta2, epsilon)\n",
        "\n",
        "    def _adam_update(self, key_tuple, grad, learning_rate, beta1, beta2, epsilon):\n",
        "        # Helper for nested param update\n",
        "        if isinstance(key_tuple, str): key_tuple = (key_tuple,)\n",
        "\n",
        "        param_ref = self.params\n",
        "        m_ref = self.adam_m\n",
        "        v_ref = self.adam_v\n",
        "        for key in key_tuple:\n",
        "            param_ref = param_ref[key]\n",
        "            m_ref = m_ref[key]\n",
        "            v_ref = v_ref[key]\n",
        "\n",
        "        m_ref[...] = beta1 * m_ref + (1 - beta1) * grad\n",
        "        v_ref[...] = beta2 * v_ref + (1 - beta2) * (grad**2)\n",
        "        m_hat = m_ref / (1 - beta1**self.adam_t)\n",
        "        v_hat = v_ref / (1 - beta2**self.adam_t)\n",
        "        param_ref[...] -= learning_rate * m_hat / (np.sqrt(v_hat) + epsilon)\n",
        "\n",
        "    def predict(self, X):\n",
        "        probs, _ = self.forward(X)\n",
        "        return np.argmax(probs, axis=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "34Z9f7f7mVXK"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L82mShY3mVgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "GUleTOx162m2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN"
      ],
      "metadata": {
        "id": "SR282cI466By"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Recommended Hyperparameters ---\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 16      # CRITICAL: Increase this back to 128 or even 256\n",
        "VOCAB_SIZE = 15000    # Use a larger vocabulary\n",
        "BATCH_SIZE = 256      # 64 is a good starting point\n",
        "NUM_EPOCHS = 20       # CRITICAL: Train for more epochs since the model was still learning\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "# --- Adam Hyperparameters ---\n",
        "BETA1 = 0.9\n",
        "BETA2 = 0.999\n",
        "EPSILON = 1e-8\n",
        "\n",
        "# Define the output dimension based on the number of unique labels\n",
        "OUTPUT_DIM = len(label_to_idx)\n",
        "\n",
        "# --- 2. Initialize the Model ---\n",
        "model = RNN(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    embedding_dim=EMBEDDING_DIM,\n",
        "    hidden_dim=HIDDEN_DIM,\n",
        "    output_dim=OUTPUT_DIM\n",
        ")\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    epoch_loss = 0\n",
        "    train_batches = create_mini_batches(X_train, y_train, BATCH_SIZE)\n",
        "\n",
        "    for i, (X_batch, y_batch) in enumerate(train_batches):\n",
        "        probs, cache = model.forward(X_batch)\n",
        "        loss = model.compute_loss(probs, y_batch)\n",
        "        epoch_loss += loss\n",
        "\n",
        "        grads = model.backward(y_batch, cache)\n",
        "        model.update_params_with_adam(grads, LEARNING_RATE, BETA1, BETA2, EPSILON)\n",
        "\n",
        "        if i % 50 == 0:\n",
        "            sys.stdout.write(f\"\\rEpoch {epoch+1}/{NUM_EPOCHS} | Batch {i} | Loss: {loss:.4f}\")\n",
        "\n",
        "    avg_epoch_loss = epoch_loss / (i + 1)\n",
        "    val_preds = model.predict(X_val[:2000])  # Increase validation size\n",
        "    val_accuracy = np.mean(val_preds == y_val[:2000])\n",
        "\n",
        "    print(f\"\\nEnd of Epoch {epoch+1} | Avg Loss: {avg_epoch_loss:.4f} | Val Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "# --- 5. Final Evaluation on Test Set ---\n",
        "print(\"\\nTraining finished. Evaluating on test set...\")\n",
        "test_preds = model.predict(X_test)\n",
        "\n",
        "# Calculate both accuracy and macro F1-score\n",
        "test_accuracy, test_macro_f1 = calculate_metrics(y_test, test_preds, model.output_dim)\n",
        "\n",
        "print(f\"Final Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Final Test Macro F1-Score: {test_macro_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xufHuBrZ64iq",
        "outputId": "ddedb5f4-818c-4e6c-8710-6393249fe295"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 | Batch 100 | Loss: 1.6020\n",
            "End of Epoch 1 | Avg Loss: 1.5748 | Val Accuracy: 0.2985\n",
            "Epoch 2/20 | Batch 100 | Loss: 1.4195\n",
            "End of Epoch 2 | Avg Loss: 1.4595 | Val Accuracy: 0.3535\n",
            "Epoch 3/20 | Batch 100 | Loss: 1.3209\n",
            "End of Epoch 3 | Avg Loss: 1.2747 | Val Accuracy: 0.4250\n",
            "Epoch 4/20 | Batch 100 | Loss: 1.1264\n",
            "End of Epoch 4 | Avg Loss: 1.1504 | Val Accuracy: 0.4050\n",
            "Epoch 5/20 | Batch 100 | Loss: 1.1125\n",
            "End of Epoch 5 | Avg Loss: 1.0682 | Val Accuracy: 0.4300\n",
            "Epoch 6/20 | Batch 100 | Loss: 1.0442\n",
            "End of Epoch 6 | Avg Loss: 1.0014 | Val Accuracy: 0.4175\n",
            "Epoch 7/20 | Batch 100 | Loss: 1.0513\n",
            "End of Epoch 7 | Avg Loss: 0.9445 | Val Accuracy: 0.4190\n",
            "Epoch 8/20 | Batch 100 | Loss: 0.8426\n",
            "End of Epoch 8 | Avg Loss: 0.9087 | Val Accuracy: 0.4175\n",
            "Epoch 9/20 | Batch 100 | Loss: 0.7640\n",
            "End of Epoch 9 | Avg Loss: 0.8584 | Val Accuracy: 0.4065\n",
            "Epoch 10/20 | Batch 100 | Loss: 0.7682\n",
            "End of Epoch 10 | Avg Loss: 0.8342 | Val Accuracy: 0.4030\n",
            "Epoch 11/20 | Batch 100 | Loss: 0.8194\n",
            "End of Epoch 11 | Avg Loss: 0.8008 | Val Accuracy: 0.4090\n",
            "Epoch 12/20 | Batch 100 | Loss: 0.7899\n",
            "End of Epoch 12 | Avg Loss: 0.7649 | Val Accuracy: 0.3965\n",
            "Epoch 13/20 | Batch 100 | Loss: 0.7809\n",
            "End of Epoch 13 | Avg Loss: 0.7366 | Val Accuracy: 0.4120\n",
            "Epoch 14/20 | Batch 100 | Loss: 0.7380\n",
            "End of Epoch 14 | Avg Loss: 0.7130 | Val Accuracy: 0.4045\n",
            "Epoch 15/20 | Batch 100 | Loss: 0.6832\n",
            "End of Epoch 15 | Avg Loss: 0.6897 | Val Accuracy: 0.4070\n",
            "Epoch 16/20 | Batch 100 | Loss: 0.6061\n",
            "End of Epoch 16 | Avg Loss: 0.6819 | Val Accuracy: 0.3910\n",
            "Epoch 17/20 | Batch 100 | Loss: 0.6104\n",
            "End of Epoch 17 | Avg Loss: 0.6504 | Val Accuracy: 0.4045\n",
            "Epoch 18/20 | Batch 100 | Loss: 0.6780\n",
            "End of Epoch 18 | Avg Loss: 0.6131 | Val Accuracy: 0.3940\n",
            "Epoch 19/20 | Batch 100 | Loss: 0.5252\n",
            "End of Epoch 19 | Avg Loss: 0.5795 | Val Accuracy: 0.3950\n",
            "Epoch 20/20 | Batch 100 | Loss: 0.5370\n",
            "End of Epoch 20 | Avg Loss: 0.5626 | Val Accuracy: 0.3940\n",
            "\n",
            "Training finished. Evaluating on test set...\n",
            "Final Test Accuracy: 0.3691\n",
            "Final Test Macro F1-Score: 0.3744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_model(model, word_to_idx, label_to_idx, '/content/sample_data/model_RNN.npz')"
      ],
      "metadata": {
        "id": "YAEJtHDO7AMy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1613ab22-1798-44ba-fb75-df25ff9180f3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/sample_data/model_RNN.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM\n"
      ],
      "metadata": {
        "id": "keTlj6VYT3Y3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Model & Training Hyperparameters ---\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 16\n",
        "OUTPUT_DIM = len(label_to_idx)\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# --- Adam Hyperparameters ---\n",
        "BETA1 = 0.9\n",
        "BETA2 = 0.999\n",
        "\n",
        "# --- 2. Initialize the Model ---\n",
        "# The only change is here: instantiate LSTM instead of RNN\n",
        "model = LSTM(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    embedding_dim=EMBEDDING_DIM,\n",
        "    hidden_dim=HIDDEN_DIM,\n",
        "    output_dim=OUTPUT_DIM\n",
        ")\n",
        "\n",
        "# --- 3. The Training Loop (Identical to before) ---\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    epoch_loss = 0\n",
        "    train_batches = create_mini_batches(X_train, y_train, BATCH_SIZE)\n",
        "\n",
        "    for i, (X_batch, y_batch) in enumerate(train_batches):\n",
        "        probs, cache = model.forward(X_batch)\n",
        "        loss = model.compute_loss(probs, y_batch)\n",
        "        epoch_loss += loss\n",
        "\n",
        "        grads = model.backward(y_batch, cache)\n",
        "        model.update_params_with_adam(grads, LEARNING_RATE, BETA1, BETA2)\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            sys.stdout.write(f\"\\rEpoch {epoch+1}/{NUM_EPOCHS} | Batch {i} | Loss: {loss:.4f}\")\n",
        "\n",
        "    avg_epoch_loss = epoch_loss / (i + 1)\n",
        "    val_preds = model.predict(X_val[:2000])\n",
        "    val_accuracy = np.mean(val_preds == y_val[:2000])\n",
        "\n",
        "    print(f\"\\nEnd of Epoch {epoch+1} | Avg Loss: {avg_epoch_loss:.4f} | Val Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "\n",
        "print(\"\\nTraining finished. Evaluating on test set...\")\n",
        "test_preds = model.predict(X_test)\n",
        "\n",
        "# Calculate both accuracy and macro F1-score\n",
        "test_accuracy, test_macro_f1 = calculate_metrics(y_test, test_preds, model.output_dim)\n",
        "\n",
        "print(f\"Final Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Final Test Macro F1-Score: {test_macro_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmK0Nyz-T2y4",
        "outputId": "3a8d21f8-fdb3-4c7b-9c04-7db183565836"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Batch 500 | Loss: 1.4292\n",
            "End of Epoch 1 | Avg Loss: 1.5048 | Val Accuracy: 0.4125\n",
            "Epoch 2/10 | Batch 500 | Loss: 1.0756\n",
            "End of Epoch 2 | Avg Loss: 1.2261 | Val Accuracy: 0.5190\n",
            "Epoch 3/10 | Batch 500 | Loss: 0.8758\n",
            "End of Epoch 3 | Avg Loss: 1.0565 | Val Accuracy: 0.5690\n",
            "Epoch 4/10 | Batch 500 | Loss: 0.8928\n",
            "End of Epoch 4 | Avg Loss: 0.8762 | Val Accuracy: 0.6500\n",
            "Epoch 5/10 | Batch 500 | Loss: 0.8422\n",
            "End of Epoch 5 | Avg Loss: 0.6981 | Val Accuracy: 0.7000\n",
            "Epoch 6/10 | Batch 500 | Loss: 0.4923\n",
            "End of Epoch 6 | Avg Loss: 0.5600 | Val Accuracy: 0.7360\n",
            "Epoch 7/10 | Batch 500 | Loss: 0.4530\n",
            "End of Epoch 7 | Avg Loss: 0.4669 | Val Accuracy: 0.7405\n",
            "Epoch 8/10 | Batch 500 | Loss: 0.4696\n",
            "End of Epoch 8 | Avg Loss: 0.4009 | Val Accuracy: 0.7695\n",
            "Epoch 9/10 | Batch 500 | Loss: 0.3841\n",
            "End of Epoch 9 | Avg Loss: 0.3491 | Val Accuracy: 0.7740\n",
            "Epoch 10/10 | Batch 500 | Loss: 0.3913\n",
            "End of Epoch 10 | Avg Loss: 0.3252 | Val Accuracy: 0.7670\n",
            "\n",
            "Training finished. Evaluating on test set...\n",
            "Final Test Accuracy: 0.7422\n",
            "Final Test Macro F1-Score: 0.7506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_model(model, word_to_idx, label_to_idx, '/content/sample_data/model_LSTM.npz')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drr4Cl8HT21P",
        "outputId": "24d9d55a-b672-4353-b93e-4de9a827f82a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/sample_data/model_LSTM.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer"
      ],
      "metadata": {
        "id": "BsCBDkhPmJBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import sys\n",
        "\n",
        "# --- Hyperparameters ---\n",
        "VOCAB_SIZE = 15000\n",
        "MAX_LEN = 50\n",
        "EMBEDDING_DIM = 100\n",
        "NUM_HEADS = 1\n",
        "FF_HIDDEN_DIM = 128\n",
        "NUM_BLOCKS = 1\n",
        "OUTPUT_DIM = 5\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 64\n",
        "BETA1 = 0.9\n",
        "BETA2 = 0.999\n",
        "PATIENCE = 3   # NEW: Stop training if val_loss doesn't improve after 3 epochs\n",
        "\n",
        "# --- Initialize the Model ---\n",
        "model = TransformerEncoder(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    max_len=MAX_LEN,\n",
        "    embedding_dim=EMBEDDING_DIM,\n",
        "    num_heads=NUM_HEADS,\n",
        "    ff_hidden_dim=FF_HIDDEN_DIM,\n",
        "    num_blocks=NUM_BLOCKS,\n",
        "    output_dim=OUTPUT_DIM\n",
        ")\n",
        "print(\"Transformer model initialized.\")\n",
        "\n",
        "# --- Early Stopping Setup ---\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "best_model_params = None\n",
        "\n",
        "# --- Training Loop ---\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    # Training Phase\n",
        "    epoch_loss = 0\n",
        "    train_batches = create_mini_batches(X_train, y_train, BATCH_SIZE)\n",
        "    for i, (X_batch, y_batch) in enumerate(train_batches):\n",
        "        probs, cache = model.forward(X_batch)\n",
        "        loss = model.compute_loss(probs, y_batch)\n",
        "        epoch_loss += loss\n",
        "        grads = model.backward(y_batch, cache)\n",
        "        model.update_params_with_adam(grads, LEARNING_RATE, BETA1, BETA2)\n",
        "\n",
        "        if i % 10 == 0:\n",
        "            sys.stdout.write(f\"\\rEpoch {epoch+1}/{NUM_EPOCHS} | Batch {i} | Loss: {loss:.4f}\")\n",
        "\n",
        "    avg_train_loss = epoch_loss / (i + 1)\n",
        "\n",
        "    # Validation Phase\n",
        "    val_loss = 0\n",
        "    val_batches = create_mini_batches(X_val, y_val, BATCH_SIZE, shuffle=False)\n",
        "    for i, (X_batch_val, y_batch_val) in enumerate(val_batches):\n",
        "        probs, _ = model.forward(X_batch_val)\n",
        "        val_loss += model.compute_loss(probs, y_batch_val)\n",
        "    avg_val_loss = val_loss / (i + 1)\n",
        "\n",
        "    val_preds = model.predict(X_val)\n",
        "    val_accuracy, _ = calculate_metrics(y_val, val_preds, model.output_dim)\n",
        "\n",
        "    print(f\"\\nEnd of Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | \"\n",
        "          f\"Val Loss: {avg_val_loss:.4f} | Val Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    # --- Early Stopping ---\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        print(f\" Validation loss improved from {best_val_loss:.4f}  {avg_val_loss:.4f}. Saving model...\")\n",
        "        best_val_loss = avg_val_loss\n",
        "        best_model_params = copy.deepcopy(model.params)\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f\" Validation loss did not improve. Patience: {patience_counter}/{PATIENCE}\")\n",
        "\n",
        "    if patience_counter >= PATIENCE:\n",
        "        print(\" Early stopping triggered.\")\n",
        "        break\n",
        "\n",
        "# --- Final Evaluation ---\n",
        "print(\"\\nTraining finished. Loading best model and evaluating on test set...\")\n",
        "if best_model_params:\n",
        "    model.params = best_model_params  # restore best params\n",
        "\n",
        "test_preds = model.predict(X_test)\n",
        "test_accuracy, test_macro_f1 = calculate_metrics(y_test, test_preds, model.output_dim)\n",
        "print(f\"Final Test Accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Final Test Macro F1-Score: {test_macro_f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzufT2JsmOFy",
        "outputId": "0fa45455-0a2f-4a98-a380-79e5bbe4fa96"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformer model initialized.\n",
            "Epoch 1/10 | Batch 570 | Loss: 0.9092\n",
            "End of Epoch 1 | Train Loss: 1.2425 | Val Loss: 0.8979 | Val Accuracy: 0.6207\n",
            " Validation loss improved from inf  0.8979. Saving model...\n",
            "Epoch 2/10 | Batch 570 | Loss: 0.6665\n",
            "End of Epoch 2 | Train Loss: 0.6453 | Val Loss: 0.6134 | Val Accuracy: 0.7823\n",
            " Validation loss improved from 0.8979  0.6134. Saving model...\n",
            "Epoch 3/10 | Batch 570 | Loss: 0.4600\n",
            "End of Epoch 3 | Train Loss: 0.4965 | Val Loss: 0.6287 | Val Accuracy: 0.7794\n",
            " Validation loss did not improve. Patience: 1/3\n",
            "Epoch 4/10 | Batch 570 | Loss: 0.5258\n",
            "End of Epoch 4 | Train Loss: 0.4320 | Val Loss: 0.6150 | Val Accuracy: 0.7898\n",
            " Validation loss did not improve. Patience: 2/3\n",
            "Epoch 5/10 | Batch 570 | Loss: 0.4315\n",
            "End of Epoch 5 | Train Loss: 0.3998 | Val Loss: 0.6269 | Val Accuracy: 0.7935\n",
            " Validation loss did not improve. Patience: 3/3\n",
            " Early stopping triggered.\n",
            "\n",
            "Training finished. Loading best model and evaluating on test set...\n",
            "Final Test Accuracy: 0.7533\n",
            "Final Test Macro F1-Score: 0.7619\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_model(model, word_to_idx, label_to_idx, '/content/sample_data/model_Transformer_128.npz')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUm9gKwEt28B",
        "outputId": "06638e0e-e636-47c8-f93a-f371e9b4be76"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to /content/sample_data/model_Transformer_128.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_macro_f1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7goda5v_DJx",
        "outputId": "a83b47b1-946f-4c94-c914-9001e9fdb16e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.7618576316756924)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yQ0JKxW_PMRu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}